---
title: "Introduction to single-cell RNA-seq analysis"
output:
  html_document:
    toc: yes
    toc_float: true
    toc_depth: 3
    number_sections: true
    pandoc_args: ["--number-offset", "3"] # TOC will start at 4
    code_folding: show
    css: ../css/boxes.css
---

# Quality Control and Filtering

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      root.dir = here::here("course_files"))
knitr::opts_knit$set(root.dir = here::here("course_files"))
set.seed(123)
```

## Libraries, parallelisation and seed setting

We start our analysis by loading the libraries we will need for this practical. 
We will be using `Seurat` for our analysis, `sctransform` for normalisation (coming later) and `tidyverse` for data manipulation and plotting.

```{r load_libraries}
# Load the libraries we will need for this practical
library(Seurat)
library(sctransform)
library(tidyverse)
```

### Load Single Sample

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### Load data for a single sample ####
```

Reading data into Seurat can be done in two steps: 

- First, we read in the data using `Read10X()`, which reads in the count matrix and returns a list of matrices (one for each assay).
- Then we create a Seurat object using `CreateSeuratObject()`, which takes the count matrix and creates a Seurat object that contains the data and metadata.

```{r load}
# Read 10x data matrices
etv6_runx1_1_data <- Read10X(
  data.dir = "Data/CellRanger_Outputs/SRR9264343/outs/filtered_feature_bc_matrix/"
)

# Create Seurat object from the loaded matrices
etv6_runx1_1 <- CreateSeuratObject(
  counts = etv6_runx1_1_data,
  project = "ETV6_RUNX1_1"
)
```

### Seurat Object

https://satijalab.org/seurat/articles/essential_commands

https://biostatsquid.com/seurat-objects-explained/

```{r seurat_object}
# Look at the structure of the Seurat object
etv6_runx1_1

# The metadata can be accessed with the @meta.data slot
head(etv6_runx1_1@meta.data)

# The counts can be accessed with the @assays slot
etv6_runx1_1@assays
```

Being aware of the **active assay** is important when doing different types of analysis because tools will try to use the active assay by default if they can. 
Note that normally raw counts (the RNA assay) are used for differential expression e.g. calling markers. 
Conversely, normalised data is used to identify cell types e.g. in drawing UMAP plots.
Here, we start by defining our default assay to the raw counts, using the `DefaultAssay()` function:

```{r DefaultAssay}
# Set the default assay to RNA (raw counts)
DefaultAssay(etv6_runx1_1) <- "RNA"

# Check the active assay was set correctly
etv6_runx1_1@active.assay
```

For convenience, we pull the raw counts matrix for the RNA assay out of the Seurat object and into a separate variable for exploratory analysis and QC. 
This is not strictly necessary but it can be easier to work with the raw counts matrix directly for some of these steps.

```{r raw_counts}
# Pull out the raw counts matrix for the RNA assay for exploratory analysis and QC
raw_counts <- etv6_runx1_1@assays$RNA$counts
```

## Properties of Single cell data

### Number of genes detected per cell

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### Genes detected per cell ####
```

```{r genes_per_cell}
# Calculate the number of genes detected per cell
genes_per_cell <- colSums(raw_counts > 0)

# Plot the distribution of genes detected per cell
plot(density(genes_per_cell),
     main = "",
     xlab = "Genes per cell")
```

### Total UMI for a gene versus the number of times detected

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### Total UMIs vs detected cells ####
```


If we compare the number of UMI's assigned to an individual gene to the number of cells in which that gene is detected, we can see that highly expressed genes tend to be detected in a higher proportion of cells than lowly expressed genes.

```{r expression_vs_detected}
# Calculate the mean UMIs per cell for each gene
mean_umis_per_cell <- rowSums(raw_counts) / (rowSums(raw_counts) > 0)

# Calculate the proportion of cells expressing each gene
proportion_cells_expressing <- rowMeans(raw_counts > 0)

# Plot the relationship between mean UMIs per cell and proportion of cells expressing the gene
plot(
  x = mean_umis_per_cell,
  y = proportion_cells_expressing,
  log = "x",
  xlab = "Mean UMIs per cell",
  ylab = "Proportion of cells expressing the gene"
)
```

### Distribution of counts for a gene across cells

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### Gene count distribution ####
```

We could also look at the distribution of counts for individual genes across all cells. The plot below shows this distribution for the top 20 genes detected.

```{r gene_count_distribution, fig.height=6}
# Calculate the relative expression of each gene in each cell
rel_expression <- t(t(raw_counts) / colSums(raw_counts)) * 100

# Get the 20 most expressed genes
most_expressed <- sort(rowSums(rel_expression), decreasing = TRUE)[20:1]

# Plot the distribution of relative expression for the top 20 genes
plot_data <- as.matrix(t(rel_expression[names(most_expressed), ]))

boxplot(plot_data, cex = 0.1, las = 1,
        xlab = "% total count per cell",
        horizontal = TRUE)
```


## Quality Control

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### Quality control filtering ####
```

The cell calling performed by CellRanger does not always retain only droplets
containing cells. Poor-quality cells, or rather droplets, may be caused
by cell damage during dissociation or failed library preparation. They usually
have low UMI counts, few genes detected and/or high mitochondrial content. The
presence of these droplets in the data set may affect normalisation, assessment
of cell population heterogeneity, and clustering:

* Normalisation: Contaminating genes, 'the ambient RNA', are detected at low
levels in all libraries. In low quality libraries with low RNA content, scaling
will increase counts for these genes more than for better-quality cells,
resulting in their apparent upregulation in these cells and increased variance
overall.  
* Cell population heterogeneity: variance estimation and dimensionality
reduction with PCA where the first principal component will be correlated with
library size, rather than biology.  
* Clustering: higher mitochondrial and/or nuclear RNA content may cause
low-quality cells to cluster separately or form states or trajectories between
distinct cell types.

In order to remove or reduce the impact of poor-quality droplets on our 
downstream analysis we will attempt to filter them out using some QC metrics.
The three principle means of doing this are to apply thresholds for inclusion
on three characteristics:

* The **library size** defined as the total sum of UMI counts across all genes;
  cells with small library sizes are considered to be of low quality as the RNA
  has not been efficiently captured, i.e. converted into cDNA and amplified,
  during library preparation.

* The **number of expressed genes in each cell** defined as the number of genes
  with non-zero counts for that cell; any cell with very few expressed genes is
  likely to be of poor quality as the diverse transcript population has not
  been successfully captured.

* The **proportion of UMIs mapped to genes in the mitochondrial genome**; high
  proportions are indicative of poor-quality cells, possibly because of loss of
  cytoplasmic RNA from perforated cells (the reasoning is that mitochondria are
  larger than individual transcript molecules and less likely to escape through
  tears in the cell membrane).

### Detected Genes

Another simple metric that we can quickly calculate is the **number of genes detected** in the whole dataset (i.e. those that are true for this statement):

```{r genes_detected}
# How many genes are detected in the whole dataset?
table(rowSums(raw_counts) > 0)
```

### Mitochondrial Gene Content

To calculate the percentage of mitochondrial genes, we first need to identify which genes are mitochondrial. To get these numbers we can take advantage of the fact that (in human) all mitochondrial gene names start with the 'MT-' prefix. 
This is probably not the case for your non-human species of interest, although for mouse it is usually 'Mt'. The [[ operator can add columns to object metadata. This is a good place to store QC information.

```{r mito_genes}
# Identify mitochondrial genes
mito_genes <- grep(pattern = "^MT-",
                   x = rownames(raw_counts), value = TRUE)
length(mito_genes)

# Calculate the percentage of UMIs mapped to mitochondrial genes and add this as a column to the metadata
etv6_runx1_1[["percent.mt"]] <- PercentageFeatureSet(etv6_runx1_1,
                                                     pattern = "^MT-")

head(etv6_runx1_1@meta.data)
```

### Visualize QC Metrics

We can visualize some of these QC metrics using `VlnPlot()`, which produces violin plots. Here we will look at the number of features (genes), number of counts (UMIs) and percentage of mitochondrial genes.

```{r detected_genes}
# Distribution of number of genes detected per cell
VlnPlot(etv6_runx1_1, features = c("nFeature_RNA"), layer = "counts")
```

```{r umi_counts}
# Distribution of total UMI counts per cell
VlnPlot(etv6_runx1_1, features = c("nCount_RNA"), layer = "counts")
```

```{r mito_percent}
# Distribution of percentage of mitochondrial genes per cell
VlnPlot(etv6_runx1_1, features = c("percent.mt"), layer = "counts")
```

```{r qc_vlnplots}
# Distribution of all three QC metrics together
VlnPlot(etv6_runx1_1,
        features = c("nFeature_RNA", "nCount_RNA", "percent.mt"),
        ncol = 3, layer = "counts")
```

## Loading Multiple Samples

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### Multiple samples ####
```

If you have multiple samples to load, the Read10X function can take a named list of directories as input, and it will read in each sample and combine them into a single expression matrix with sample-specific cell barcodes. Each cell barcode is modified with the sample name to ensure uniqueness in your dataset. 

The function will make a column in the metadata called 'orig.ident' which contains the sample name for each cell. However it obtains this programmatically from the named vector. The default behaviour assumes names are sample_otherinfo. The separator can be set with `names.delim`. Warning: If your names do not follow this convention you may need to set this argument or you will end up with incomplete or nonsense samples in your object.

```{r dir_vector}
# Read our sample information sheet
sampleinfo <- read_tsv("Data/sample_sheet.tsv")

# Create a named vector of directories for each sample
# We work with a subset of samples for demonstration purposes
samples <- sampleinfo$Sample[c(1, 5, 7, 9)]
list_of_files <- file.path("Data/CellRanger_Outputs/",
                           samples,
                           "/outs/filtered_feature_bc_matrix")
names(list_of_files) <- sampleinfo$SampleName[c(1, 5, 7, 9)]
```

```{r load_multiple}
# Read in the cellranger matrices for all samples
expression_matrix <- Read10X(data.dir = list_of_files)

# Create a new seurat object with the combined expression matrix
multi_seurat_object <- CreateSeuratObject(counts = expression_matrix)
multi_seurat_object
```

### Adding Sample Metadata

Now we have our combined Seurat object we should add in some helpful metadata like which sample group or condition these samples belong to. 
Since we need the cell level information to do this the easiest way is to use the `orig.ident` column of the metadata which is where the sample name was stored when the object was made and then pass this back to the Seurat object metadata. 
Our sample names are structured in a way that makes this easy.

```{r add_metadata, warning=FALSE, message=FALSE}
# Pull out the metadata and add sample group and sample name information
temp_metadata <- multi_seurat_object@meta.data %>%
  # Add the cell barcodes as a column so we can pull them back in at the end
  rownames_to_column("Cell") %>%
  # Extract the sample group information from the origin identifier
  # The pattern "-.*" matches the first dash and everything after it
  mutate(SampleGroup = str_remove(orig.ident, "-.*")) %>% 
  # Add the sample name as a column
  mutate(SampleName = orig.ident) %>%
  # Put the cell barcodes back as rownames
  column_to_rownames("Cell")

# Add the modified metadata back to the Seurat object
multi_seurat_object@meta.data <- temp_metadata
```

### Remove undetected genes

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### QC: remove undetected genes ####
```

The first thing we should do is filter out genes that haven't been detected in our experiment. 
This will reduce the size of the Seurat Object and make processing a little faster.
We can do this using the `rowSums()` function to calculate the total counts for each gene across all cells and all samples, and then filter out genes with zero counts.

```{r filter_undetected_genes}
# How many genes are detected in the whole dataset?
table(rowSums(multi_seurat_object@assays$RNA$counts) > 0)

# Filter out genes that are not detected in any cell
filtered_multi_seurat_object <- subset(
  multi_seurat_object,
  features = rownames(multi_seurat_object)[
    Matrix::rowSums(multi_seurat_object[["RNA"]]$counts) > 0
  ]
)

# Check how many genes are detected after filtering
filtered_multi_seurat_object

# Confirm all of these now have at least 1 count across all cells
table(rowSums(filtered_multi_seurat_object@assays$RNA$counts) > 0)
```
We don't actually need to do this explicitly. `CreateSeuratObject` has an argument called `min.cells`. The documentation states: "Include features detected in at least this many cells". so by changing this to `1` (default is 0) when we create the object at the start we don't need to worry about this step.

### Visualize QC Metrics for Multiple Samples

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### QC: visualising metrics ####
```

We can visualize QC metrics for the merged samples using `VlnPlot()` again:

```{r merged_qc_vlnplots}
# Add the percentage of mitochondrial genes to the metadata
filtered_multi_seurat_object[["percent.mt"]] <-
  PercentageFeatureSet(filtered_multi_seurat_object, pattern = "^MT-")

# Plot the distribution of QC metrics for the merged samples
VlnPlot(filtered_multi_seurat_object,
  features = c("nFeature_RNA", "nCount_RNA", "percent.mt"),
  ncol = 3,
  layer = "counts"
)
```

The default plotting sytle of Seurat overlays the points on the violin. 
Sometimes this can obscure the distribution. 
To turn this off, we can set the `pt.size` parameter to `0`:

```{r merged_qc_vlnplots_no_points}
VlnPlot(
  filtered_multi_seurat_object,
  features = c("nFeature_RNA", "nCount_RNA", "percent.mt"),
  ncol = 3,
  layer = "counts",
  pt.size = 0
)
```

### Filtering out low quality droplets

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### QC: filtering low-quality droplets ####
```

One could use a hard threshold for the library size, number of genes detected and mitochondrial content based on the distributions seen above. 
These would need vary across runs and the decision making process is somewhat arbitrary. 
For example, imagine if we decided all cells should have at least 500 genes detected. 
This example also shows how you can use the Seurat ggplot nature to add a line to indicate our thresholds.

```{r arbitary_thresholds}
# Plot where we would set a threshold
VlnPlot(
  filtered_multi_seurat_object,
  features = "nFeature_RNA",
  group.by = "SampleGroup",
  layer = "counts",
  pt.size = 0
) +
  geom_hline(yintercept = 500, color = "red")
```

It may therefore be preferable to rely on outlier detection to identify cells that markedly differ from most cells.

We saw above that the distribution of the QC metrics is close to Normal. 
Hence, we can detect outliers using the median and the median absolute deviation (MAD) from the median (not the mean and the standard deviation which both are sensitive to outliers).

For a given metric, an outlier value is one that lies over some number of MADs away from the median. 
A cell will be excluded if it is an outlier in the part of the range to avoid, for example low gene counts, or high mitochondrial content. 
For a normal distribution, a threshold defined with a distance of 3 MADs from the median retains about 99% of values. 
For most experiments 2 or 3 MADs is a reasonable starting point.

The samples analysed here may have been processed in different batches leading to differences in the overall distribution of UMI counts, numbers of genes detected and mitochondrial content. 
Such differences would affect the adaptive thresholds discussed above - that is, as the distributions of the metrics differ, so we need to decide if threshold should be per batch, per sample or across all samples.

Because of the different layers, we will need to break down the object to apply different thresholds by group or sample. 
The easiest way to do this is to work with the metadata and use the cell barcodes for filtering with Seurat::subset(). 

Before generalising this filtering across all samples, let's look at a step-by-step example for one sample.

```{r filter_one_sample}
# Pull out the metadata for easier manipulation
metadata <- filtered_multi_seurat_object@meta.data

#### Example of how to filter for one sample ####

# Subset the metadata for one of the samples
e_cells <- metadata %>%
  filter(SampleName == "ETV6RUNX1-1")

# calculate the median and MAD for the number of genes detected in this sample
feature_mad <- mad(e_cells$nFeature_RNA)
feature_median <- median(e_cells$nFeature_RNA)

# set a threshold for the number of genes detected as 2 MADs below the median
feature_threshold <- feature_median - 2 * feature_mad

# How many cells would this remove?
length(e_cells$nFeature_RNA) # total cells
sum(e_cells$nFeature_RNA > feature_threshold) # cells above threshold

# The same process can be repeated for the other metrics
umi_threshold <- median(e_cells$nCount_RNA) - 2 * mad(e_cells$nCount_RNA)
sum(e_cells$nCount_RNA > umi_threshold)

# for mitochondrial content we want to set a threshold above the median
mt_threshold <- median(e_cells$percent.mt) + 2 * mad(e_cells$percent.mt)
sum(e_cells$percent.mt < mt_threshold)

# visualise the thresholds on the plot
ggplot(e_cells,
       aes(x = nFeature_RNA,
           y = nCount_RNA,
           color = percent.mt)) +
  geom_point() +
  geom_vline(xintercept = feature_threshold, color = "red") +
  geom_hline(yintercept = umi_threshold, color = "blue") +
  scale_color_viridis_c() +
  theme_minimal() +
  labs(
    title = "QC Metrics for ETV6-RUNX1_1",
    x = "Number of Features (Genes) Detected",
    y = "Number of Counts (UMIs)",
    color = "Percent Mitochondrial"
  )

# We cound apply all 3 filters together to get a vector of cell
# barcodes to keep for this sample
# using standard dplyr filtering and pulling out the cell barcodes
e_keep_cells <- metadata %>%
  rownames_to_column("Cell") %>%
  filter(SampleName == "ETV6RUNX1-1") %>%
  filter(nFeature_RNA > feature_threshold,
         nCount_RNA > umi_threshold,
         percent.mt < mt_threshold) %>%
  pull(Cell)

# check how many cells would be left for this sample
length(e_keep_cells)
```

So, this would leave us with `r length(e_keep_cells)` cells for this sample.

We can generalise this process by using the `group_by()` function from `dplyr`, which will allow us to define median/MAD thresholds _per sample_. 
Here is the combined code to do this for all samples, which you can use as a template for your own filtering:

```{r apply_filter_all_samples}
#### Apply filtering across all samples ####

all_keep_cells <- metadata %>%
  # Add the cell barcodes as a column so we can pull them back in at the end
  rownames_to_column("cell") %>%
  # Group by sample name to calculate thresholds per sample
  group_by(SampleName) %>%
  # Apply the filtering for each sample
  filter(nFeature_RNA > (median(nFeature_RNA) - 2 * mad(nFeature_RNA)),
         nCount_RNA > (median(nCount_RNA) - 2 * mad(nCount_RNA)),
         percent.mt < (median(percent.mt) + 2 * mad(percent.mt))) %>%
  # Pull out the cell barcodes for the cells that pass the filters
  pull(cell)

# How many cells would be left after filtering?
length(all_keep_cells)

# How many cells per sample
table(metadata[all_keep_cells, "SampleName"])
```

We then use this vector of cell barcodes to subset our Seurat object to retain only the high-quality cells.

```{r subset_seurat_object}
qc_seurat_object <- subset(
  filtered_multi_seurat_object,
  cells = all_keep_cells
)

VlnPlot(qc_seurat_object,
  features = c("nFeature_RNA", "nCount_RNA", "percent.mt"),
  ncol = 3,
  layer = "counts",
  pt.size = 0
)
```

## Exercises

<!-- Note: this code chunk is here so we purl it into the participant script -->
```{r include=FALSE}

#### Exercises ####

# Apply the same analysis to all 11 samples
```

In the demonstration above, we performed QC and filtering of 4 of our samples, one from each of our sample groups. 
For this practical we would like you to perform QC and filtering on the full dataset.

### Load the data

:::exercise 
In order to load the CellRanger data for all of the samples, you will first need to create a named vector of the paths to the filtered count matrix folders called `list_of_files` and then use this in the `Read10X()` function. 

```{r exr_load_data, warning=FALSE, message=FALSE}
# Read in the sample information sheet
sampleinfo <- read_tsv("Data/sample_sheet.tsv")

# Create a named vector of directories for each sample
# YOUR CODE HERE

# Read in the cellranger matrices for all samples
# YOUR CODE HERE

# Create the seurat object
# YOUR CODE HERE
```

<details><summary>Hint</summary>
The paths to `filtered_feature_bc_matrix` directories for each sample can be constructed using the **Sample** column as:

<span style = "color: #545454; font-weight: bold;">Data/CellRanger_Outputs/<span style="color: #2e2892; font-style: italic;">*Sample*</span>/outs/filtered_feature_bc_matrix</span>

You will need to use a function such as `str_c()`, `paste()` or `file.path()` to construct the paths.

The names of the vector will determine the identifer used in the cell barcodes, this should be the sample name as in the **SampleName** column of the sample sheet.

As Seurat V5 no longer supports parallelisation with `future` this step may take a couple of minutes.
</details>

<details><summary>Answer</summary>

```{r exr_load_data_answer, purl=FALSE}
# Create a named vector of directories for each sample
list_of_files <- file.path("Data/CellRanger_Outputs/",
                           sampleinfo$Sample,
                           "outs/filtered_feature_bc_matrix")
names(list_of_files) <- sampleinfo$SampleName
list_of_files

# Read in the cellranger matrices for all samples
expression_matrix <- Read10X(data.dir = list_of_files)

# Create the seurat object
seurat_object <- CreateSeuratObject(counts = expression_matrix, min.cells = 1)
seurat_object
```

</details>

:::

Once you import the objects, make sure to **adjust the metadata** as we did in the demonstration, to include the sample name and sample group obtained from the `orig.ident` column.

```{r exr_check_data_object, warning=FALSE, message=FALSE}
# Sample group and sample name information to the metadata
temp_metadata <- seurat_object@meta.data %>%
  rownames_to_column("Cell") %>%
  mutate(SampleGroup = str_remove(orig.ident, "-.*")) %>% 
  mutate(SampleName = orig.ident) %>%
  column_to_rownames("Cell")

seurat_object@meta.data <- temp_metadata
head(seurat_object@meta.data)
```

Also add the **percentage of UMIs mapped to mitochondrial genes** to the metadata:

```{r exr_add_mito}
# Add percentage of UMIs mapped to mitochondrial genes to the metadata
seurat_object[["percent.mt"]] <- PercentageFeatureSet(seurat_object,
                                                      pattern = "^MT-")
```

### Explore QC metric distribution

Before moving on to do the actual cell filtering, it is always a good idea to
explore the distribution of the metrics across the droplets.

:::exercise
Use `VlnPlot()` to generate plots showing the distributions of the total number of UMIs, the number of genes detected and percentage of UMIs aligned to mitochondrial genes across all cells for each sample.

This time we will use the cols argument and a vector of colours to make it easier to tell each sample group apart.

The code for plotting the total number of UMIs is shown below. 
You will also need to plot the the number of genes detected and percentage of UMIs aligned to mitochondrial.

```{r plot_library_size, results = 'hide', fig.width=12, fig.height=4}
# Create a vector of colours of each sample group
colours <- c("cyan3", "cyan3", "cyan3", "cyan3",
             "darkgoldenrod1", "darkgoldenrod1",
             "blue", "blue", "blue",
             "lightgreen", "lightgreen")

# Plot the distribution of total UMI counts per cell
VlnPlot(seurat_object, 
        features = c("nCount_RNA"),
        cols = colours,
        layer = "counts",
        pt.size = 0) +
  ggtitle("Total count of UMIs")
  
# Plot the distribution of number of genes detected per cell
# YOUR CODE HERE

# Plot the distribution of percentage of UMIs aligned to mitochondrial genes
# YOUR CODE HERE
```

<details><summary>Answer</summary>

```{r plot_detected_genes_answer, eval = FALSE, purl=FALSE, fig.width=12, fig.height=4}
# Plot the distribution of number of genes detected per cell
VlnPlot(seurat_object, 
        features = c("nFeature_RNA"),
        cols = colours,
        layer = "counts",
        pt.size = 0) +
  ggtitle("Detected Features")
```

```{r plot_MT_content_answer, eval = FALSE, purl=FALSE, fig.width=12, fig.height=4}
# Plot the distribution of percentage of UMIs aligned to mitochondrial genes per cell
VlnPlot(seurat_object, 
        features = c("percent.mt"), 
        cols = colours,
        layer = "counts", 
        pt.size = 0) +
  ggtitle("Mitochondrial Percentage")
```

</details>

:::

### Identification of low-quality cells with adaptive thresholds

:::exercise

With these samples we have three possible "batch" levels at which we could run adaptive filtering. 
We could apply the filtering across all samples together (i.e. no batch), we could apply it by sample group (ETV6-RUNX1, HHD, PBMMC, PRE-T), or we could apply it per sample.  

- How many cells will be removed from the data set if we used **sample group**?
- And do you think this is a reasonable method to choose?
- How would you decide?

```{r exr_filter_by_sample_group}
# Extract the metadata for filtering
metadata <- seurat_object@meta.data

# Apply the filtering at the SampleGroup level
# YOUR CODE HERE

# Number of cells that would be removed
# YOUR CODE HERE
```

<details><summary>Hint</summary>

Use the code from the demonstration to set thresholds at a `SampleGroup` level rather than for every sample. 
Change the filtering of the metadata to get only the cells you want.

</details>

<details><summary>Answer</summary>

```{r exr_filter_answer, purl=FALSE}
# Extract the metadata for filtering
metadata <- seurat_object@meta.data

# Apply the filtering at the SampleGroup level
sample_group_keep_cells <- metadata %>%
  rownames_to_column("Cell") %>%
  group_by(SampleGroup) %>%
  filter(nFeature_RNA > (median(nFeature_RNA) - 2 * mad(nFeature_RNA)),
         nCount_RNA > (median(nCount_RNA) - 2 * mad(nCount_RNA)),
         percent.mt < (median(percent.mt) + 2 * mad(percent.mt))) %>%
  ungroup() %>%
  pull(Cell)

# Number of cells that would be removed
nrow(metadata) - length(sample_group_keep_cells)
```

In total `r nrow(metadata) - length(sample_group_keep_cells)` cells will be removed from the dataset.

From our violin plots, it is clear that there are different distribution profiles between samples in the same group. 
Noticeably the distribution profiles for the two HDD samples are quite different. 
For this reason it may be prudent to apply the adaptive filtering to each sample independently.

We could do so, by creating a vector of cells to keep for each sample instead. 
The only change in the code is how we group the data frame before applying the filter, we group by `SampleName` instead of `SampleGroup`:

```{r exr_filter_by_sample_name, purl=FALSE}
# Apply the filtering at the SampleName level
sample_name_keep_cells <- metadata %>%
  rownames_to_column("Cell") %>%
  group_by(SampleName) %>%
  filter(nFeature_RNA > (median(nFeature_RNA) - 2 * mad(nFeature_RNA)),
         nCount_RNA > (median(nCount_RNA) - 2 * mad(nCount_RNA)),
         percent.mt < (median(percent.mt) + 2 * mad(percent.mt))) %>%
  ungroup() %>%
  pull(Cell)

# Number of cells that would be removed
nrow(metadata) - length(sample_name_keep_cells)
```

Which of these filters should we choose?

Making some visualisations of our data may help us decide. 
First, let's add this information back to the metadata so we can use it for plotting.

```{r exr_update_metadata, purl=FALSE}
new_metadata <- metadata %>%
  rownames_to_column("Cell") %>%
  mutate(sample_name_keep = Cell %in% sample_name_keep_cells,
         sample_group_keep = Cell %in% sample_group_keep_cells) %>%
  column_to_rownames("Cell")

# We can optionally add this metadata to our object
seurat_object@meta.data <- new_metadata
```

We can make a quick tally of how many cells are kept by each method for each sample:

```{r exr_tally_filters, purl=FALSE}
# Tally of how many cells are kept by each method for each sample
table(new_metadata$sample_name_keep, new_metadata$sample_group_keep)
```

We can see that in general most cells would be kept by either filter. 
However, there are some differences on cells that would pass one way of filtering but not the other. 

We can make different visualisations of our QC filters using the new metadata. 
In these examples we use standard `ggplot` code, with the `ggbeeswarm::geom_quasirandom()` function to make violin-like plots that display individual data points.
This is so we can see more clearly which cells are being filtered out by each method. 

```{r exr_plot_qc_filters, purl=FALSE}
# We sort the table by the filter so that the cells that are filtered out appear on top
new_metadata %>%
  arrange(desc(sample_group_keep)) %>%
  ggplot(aes(x = SampleName, y = nCount_RNA, 
             colour = sample_group_keep)) +
  ggbeeswarm::geom_quasirandom(size = 0.5) +
  ggtitle("Total count of UMIs")

new_metadata %>%
  arrange(desc(sample_name_keep)) %>%
  ggplot(aes(x = SampleName, y = nCount_RNA, 
             colour = sample_name_keep)) +
  ggbeeswarm::geom_quasirandom(size = 0.5) +
  ggtitle("Total count of UMIs")
```

You could also do the same for other metrics. 

</details>

:::

Once we are happy with our filtering, we can remove the cells from the Seurat object.

```{r exr_filter_seurat_object, purl=FALSE}
filtered_seurat_object <- subset(seurat_object, 
                                 cells = sample_name_keep_cells)
```

----

<details><summary>`sessionInfo()`</summary>

```{r session_info, echo=FALSE, purl=FALSE}
sessionInfo()
```

</details>
